{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyMYDOFWa7oj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting G-Drive"
      ],
      "metadata": {
        "id": "xHOG9IR15pEL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Clde-4bmDn",
        "outputId": "a5bcf035-d9e6-40cc-a36a-173b9a7d07d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbXNZY2Pbm0V",
        "outputId": "1f468f97-1f43-497c-f94f-baf4c2f49f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1zOq3j9sgb3a6ckE7CYdVuoQTgI6C-ogo/AI_Project _stuff\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/AI_Project _stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "iUhcW_llcIrC",
        "outputId": "d08e0182-a22d-4449-fab1-f07ba97e686a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1zOq3j9sgb3a6ckE7CYdVuoQTgI6C-ogo/AI_Project _stuff'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRqSWKAlcL7f",
        "outputId": "6f3e74d7-9411-42b2-8dc9-af5908feba74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GS-WGAN'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 122 (delta 63), reused 94 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (122/122), 262.30 KiB | 3.05 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DingfanChen/GS-WGAN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz2jbiAlciD4",
        "outputId": "910b08fd-c2b9-47b1-e39a-fbce699ac33f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1zOq3j9sgb3a6ckE7CYdVuoQTgI6C-ogo/AI_Project _stuff/GS-WGAN\n"
          ]
        }
      ],
      "source": [
        "%cd GS-WGAN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyHL_gcY3-zX",
        "outputId": "07e2d3d2-3245-45b3-907b-ff941f7ace99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_Project _stuff/GS-WGAN\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Requirements"
      ],
      "metadata": {
        "id": "KONj9B2o5x8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC_fE7PKcRWi",
        "outputId": "0a6bdcfa-96ee-418c-994b-8b0e78685bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: autodp in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.2.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.0.3)\n",
            "Requirement already satisfied: progress in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from autodp->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from autodp->-r requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 1)) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qBQrvJZcdw2",
        "outputId": "c63fb4a7-7064-41c9-bd2b-864d5b617c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source\n"
          ]
        }
      ],
      "source": [
        "%cd source"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attempting Pretraining"
      ],
      "metadata": {
        "id": "U-q2fG9T53Vk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5LSpymMct0W",
        "outputId": "b53bb44c-de0a-480e-e532-8ce7a1c5f2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random_seed:1\n",
            "\n",
            "dataset:fashionmnist\n",
            "\n",
            "num_discriminators:1000\n",
            "\n",
            "noise_multiplier:0.0\n",
            "\n",
            "z_dim:10\n",
            "\n",
            "model_dim:64\n",
            "\n",
            "batchsize:32\n",
            "\n",
            "L_gp:10\n",
            "\n",
            "L_epsilon:0.001\n",
            "\n",
            "critic_iters:5\n",
            "\n",
            "latent_type:bernoulli\n",
            "\n",
            "iterations:20000\n",
            "\n",
            "pretrain_iterations:2000\n",
            "\n",
            "num_workers:0\n",
            "\n",
            "net_ids:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "\n",
            "print_step:100\n",
            "\n",
            "vis_step:1000\n",
            "\n",
            "save_step:5000\n",
            "\n",
            "load_dir:None\n",
            "\n",
            "pretrain:True\n",
            "\n",
            "num_gpus:1\n",
            "\n",
            "gen_arch:ResNet\n",
            "\n",
            "run:1\n",
            "\n",
            "exp_name:ResNet_default\n",
            "\n",
            "save_dir:./../results/fashionmnist/pretrain/ResNet_default\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./../data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 26421880/26421880 [00:01<00:00, 14162580.20it/s]\n",
            "Extracting ./../data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./../data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 29515/29515 [00:00<00:00, 277156.86it/s]\n",
            "Extracting ./../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./../data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 4422102/4422102 [00:00<00:00, 5090967.01it/s]\n",
            "Extracting ./../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./../data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 5148/5148 [00:00<00:00, 45266828.08it/s]\n",
            "Extracting ./../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./../data/FashionMNIST/raw\n",
            "\n",
            "creat indices file\n",
            "Size of the dataset:  60\n",
            "G_cost:0.7403979897499084, D_cost:6.644027233123779, Wasserstein:0.4345109462738037\n",
            "G_cost:0.025183917954564095, D_cost:5.468588352203369, Wasserstein:0.3381187319755554\n",
            "G_cost:-0.043558187782764435, D_cost:1.8308767080307007, Wasserstein:1.5466275215148926\n",
            "G_cost:-0.1735537201166153, D_cost:-4.148987770080566, Wasserstein:4.518170356750488\n",
            "G_cost:-1.3004130125045776, D_cost:-6.898342132568359, Wasserstein:7.2884111404418945\n",
            "G_cost:6.704985618591309, D_cost:-7.8689961433410645, Wasserstein:9.538567543029785\n",
            "G_cost:6.593254566192627, D_cost:-8.839713096618652, Wasserstein:10.494363784790039\n",
            "G_cost:4.87760591506958, D_cost:-6.644516944885254, Wasserstein:7.707141876220703\n",
            "G_cost:0.15231260657310486, D_cost:-3.6214256286621094, Wasserstein:3.859907627105713\n",
            "G_cost:1.359318733215332, D_cost:-4.147629737854004, Wasserstein:4.518166542053223\n",
            "G_cost:-0.011937685310840607, D_cost:-3.9968204498291016, Wasserstein:4.457806587219238\n",
            "G_cost:1.3942328691482544, D_cost:-3.88535737991333, Wasserstein:4.3203840255737305\n",
            "G_cost:-1.4786291122436523, D_cost:-3.344881534576416, Wasserstein:3.6175754070281982\n",
            "G_cost:1.1632447242736816, D_cost:-3.669034481048584, Wasserstein:4.07830810546875\n",
            "G_cost:2.705517530441284, D_cost:-3.1965668201446533, Wasserstein:3.6242806911468506\n",
            "G_cost:-1.75178861618042, D_cost:-3.379405975341797, Wasserstein:3.583259105682373\n",
            "G_cost:-0.614548921585083, D_cost:-3.1878302097320557, Wasserstein:3.669886827468872\n",
            "G_cost:-0.9580473899841309, D_cost:-3.1743381023406982, Wasserstein:3.4872212409973145\n",
            "G_cost:-1.5169589519500732, D_cost:-3.233294725418091, Wasserstein:3.564650774002075\n",
            "G_cost:-0.1863776594400406, D_cost:-2.508376359939575, Wasserstein:2.7599167823791504\n",
            "G_cost:1.1256897449493408, D_cost:-1.9881610870361328, Wasserstein:2.340519905090332\n",
            "G_cost:-0.25619107484817505, D_cost:-2.2900443077087402, Wasserstein:2.45888090133667\n",
            "G_cost:1.017815113067627, D_cost:-2.2198824882507324, Wasserstein:2.491572618484497\n",
            "G_cost:1.2710727453231812, D_cost:-2.462812900543213, Wasserstein:2.588657855987549\n",
            "G_cost:1.361985206604004, D_cost:-1.908372163772583, Wasserstein:2.063047409057617\n",
            "G_cost:0.12873995304107666, D_cost:7.028958797454834, Wasserstein:0.20905005931854248\n",
            "G_cost:-0.3310962915420532, D_cost:5.231807708740234, Wasserstein:0.4591216742992401\n",
            "G_cost:-0.5977448225021362, D_cost:3.3016631603240967, Wasserstein:0.036434710025787354\n",
            "G_cost:-0.44246506690979004, D_cost:1.635400652885437, Wasserstein:-0.023395836353302002\n",
            "G_cost:-0.7163323163986206, D_cost:1.0718690156936646, Wasserstein:0.09047555923461914\n",
            "G_cost:6.731687545776367, D_cost:-16.108776092529297, Wasserstein:21.315624237060547\n",
            "G_cost:3.026803970336914, D_cost:-8.166339874267578, Wasserstein:9.516505241394043\n",
            "G_cost:7.536570072174072, D_cost:-10.20840072631836, Wasserstein:12.161552429199219\n",
            "G_cost:3.691561698913574, D_cost:-5.604466915130615, Wasserstein:6.179112434387207\n",
            "G_cost:1.3226606845855713, D_cost:-3.52475643157959, Wasserstein:3.8280880451202393\n",
            "G_cost:-0.3123553693294525, D_cost:-3.419417381286621, Wasserstein:3.7928452491760254\n",
            "G_cost:-1.3261486291885376, D_cost:-3.559373378753662, Wasserstein:3.941488265991211\n",
            "G_cost:2.1049699783325195, D_cost:-3.4361748695373535, Wasserstein:3.658780574798584\n",
            "G_cost:-1.3993513584136963, D_cost:-3.074965715408325, Wasserstein:3.324113368988037\n",
            "G_cost:2.010118007659912, D_cost:-2.8954720497131348, Wasserstein:3.225310802459717\n",
            "G_cost:2.1060378551483154, D_cost:-2.954207181930542, Wasserstein:3.348407745361328\n",
            "G_cost:0.598583996295929, D_cost:-2.8003768920898438, Wasserstein:3.1359245777130127\n",
            "G_cost:1.925391674041748, D_cost:-2.6960346698760986, Wasserstein:2.933088541030884\n",
            "G_cost:0.7925221920013428, D_cost:-2.21585750579834, Wasserstein:2.434206008911133\n",
            "G_cost:1.3485912084579468, D_cost:-2.121262311935425, Wasserstein:2.3399643898010254\n",
            "G_cost:1.7138195037841797, D_cost:-2.29595685005188, Wasserstein:2.4538023471832275\n",
            "G_cost:0.7830333113670349, D_cost:-1.6294711828231812, Wasserstein:1.7379260063171387\n",
            "G_cost:0.8495093584060669, D_cost:-1.5653375387191772, Wasserstein:1.6991443634033203\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source/pretrain.py\", line 223, in <module>\n",
            "    main(args)\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source/pretrain.py\", line 197, in main\n",
            "    fake = netG(noisev, label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source/models.py\", line 119, in forward\n",
            "    output = self.block2(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source/models.py\", line 39, in forward\n",
            "    h = self.conv1(h)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source/ops.py\", line 110, in forward\n",
            "    self._update_u_v()\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source/ops.py\", line 79, in _update_u_v\n",
            "    setattr(self.module, self.name, w / sigma.expand_as(w))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1675, in __getattr__\n",
            "    def __getattr__(self, name: str) -> Any:\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!sh pretrain.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Yg97Sugrur3",
        "outputId": "a5ea0f67-b4e9-4324-929b-4692ffa4c970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source\n"
          ]
        }
      ],
      "source": [
        "%cd source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOxIi0_0cxGG",
        "outputId": "b6184015-831b-4d89-8a93-17003cbf2a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] [--random_seed RANDOM_SEED] [--dataset {mnist,fashionmnist}]\n",
            "               [--num_discriminators NUM_DISCRIMINATORS] [--noise_multiplier NOISE_MULTIPLIER]\n",
            "               [--z_dim Z_DIM] [--model_dim MODEL_DIM] [--batchsize BATCHSIZE] [--L_gp L_GP]\n",
            "               [--L_epsilon L_EPSILON] [--critic_iters CRITIC_ITERS]\n",
            "               [--latent_type {normal,bernoulli}] [--iterations ITERATIONS]\n",
            "               [--pretrain_iterations PRETRAIN_ITERATIONS] [--num_workers NUM_WORKERS]\n",
            "               [--net_ids NET_IDS [NET_IDS ...]] [--print_step PRINT_STEP] [--vis_step VIS_STEP]\n",
            "               [--save_step SAVE_STEP] [--load_dir LOAD_DIR] [--pretrain] [--num_gpus NUM_GPUS]\n",
            "               [--gen_arch {DCGAN,ResNet}] [--run RUN] [--exp_name EXP_NAME]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --random_seed RANDOM_SEED, -s RANDOM_SEED\n",
            "                        random seed\n",
            "  --dataset {mnist,fashionmnist}, -data {mnist,fashionmnist}\n",
            "                        dataset name\n",
            "  --num_discriminators NUM_DISCRIMINATORS, -ndis NUM_DISCRIMINATORS\n",
            "                        number of discriminators\n",
            "  --noise_multiplier NOISE_MULTIPLIER, -noise NOISE_MULTIPLIER\n",
            "                        noise multiplier\n",
            "  --z_dim Z_DIM, -zdim Z_DIM\n",
            "                        latent code dimensionality\n",
            "  --model_dim MODEL_DIM, -mdim MODEL_DIM\n",
            "                        model dimensionality\n",
            "  --batchsize BATCHSIZE, -bs BATCHSIZE\n",
            "                        batch size\n",
            "  --L_gp L_GP, -lgp L_GP\n",
            "                        gradient penalty lambda hyperparameter\n",
            "  --L_epsilon L_EPSILON, -lep L_EPSILON\n",
            "                        epsilon penalty (used in PGGAN)\n",
            "  --critic_iters CRITIC_ITERS, -diters CRITIC_ITERS\n",
            "                        number of critic iters per gen iter\n",
            "  --latent_type {normal,bernoulli}, -latent {normal,bernoulli}\n",
            "                        latent distribution\n",
            "  --iterations ITERATIONS, -iters ITERATIONS\n",
            "                        iterations for training\n",
            "  --pretrain_iterations PRETRAIN_ITERATIONS, -piters PRETRAIN_ITERATIONS\n",
            "                        iterations for pre-training\n",
            "  --num_workers NUM_WORKERS, -nwork NUM_WORKERS\n",
            "                        number of workers\n",
            "  --net_ids NET_IDS [NET_IDS ...], -ids NET_IDS [NET_IDS ...]\n",
            "                        the index list for the discriminator\n",
            "  --print_step PRINT_STEP, -pstep PRINT_STEP\n",
            "                        number of steps to print\n",
            "  --vis_step VIS_STEP, -vstep VIS_STEP\n",
            "                        number of steps to vis & eval\n",
            "  --save_step SAVE_STEP, -sstep SAVE_STEP\n",
            "                        number of steps to save\n",
            "  --load_dir LOAD_DIR, -ldir LOAD_DIR\n",
            "                        checkpoint dir (for loading pre-trained models)\n",
            "  --pretrain            if performing pre-training\n",
            "  --num_gpus NUM_GPUS, -ngpus NUM_GPUS\n",
            "                        number of gpus\n",
            "  --gen_arch {DCGAN,ResNet}, -gen {DCGAN,ResNet}\n",
            "                        generator architecture\n",
            "  --run RUN, -run RUN   index number of run\n",
            "  --exp_name EXP_NAME, -name EXP_NAME\n",
            "                        output folder name; will be automatically generated if not specified\n"
          ]
        }
      ],
      "source": [
        "!python main.py -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7bCIojBFrAH"
      },
      "source": [
        "#Training the generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGfhm8C5FvZS"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijnimOcEFxpZ",
        "outputId": "41150cfe-d78b-49e6-eaa0-18ca88a2f460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source\n"
          ]
        }
      ],
      "source": [
        "%cd ../source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_42ncYRHF0HT",
        "outputId": "75367354-80ca-44e2-cfef-1e6596c73e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random_seed:1\n",
            "\n",
            "dataset:mnist\n",
            "\n",
            "num_discriminators:1000\n",
            "\n",
            "noise_multiplier:1.07\n",
            "\n",
            "z_dim:10\n",
            "\n",
            "model_dim:64\n",
            "\n",
            "batchsize:32\n",
            "\n",
            "L_gp:10\n",
            "\n",
            "L_epsilon:0.001\n",
            "\n",
            "critic_iters:5\n",
            "\n",
            "latent_type:bernoulli\n",
            "\n",
            "iterations:20000\n",
            "\n",
            "pretrain_iterations:2000\n",
            "\n",
            "num_workers:0\n",
            "\n",
            "net_ids:None\n",
            "\n",
            "print_step:100\n",
            "\n",
            "vis_step:1000\n",
            "\n",
            "save_step:5000\n",
            "\n",
            "load_dir:../results/mnist/pretrain/ResNet_default\n",
            "\n",
            "pretrain:False\n",
            "\n",
            "num_gpus:1\n",
            "\n",
            "gen_arch:ResNet\n",
            "\n",
            "run:1\n",
            "\n",
            "exp_name:ResNet_default\n",
            "\n",
            "save_dir:./../results/mnist/main/ResNet_default\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "Load NetD  0\n",
            "Load NetD  1\n",
            "Load NetD  2\n",
            "Load NetD  3\n",
            "Load NetD  4\n",
            "Load NetD  5\n",
            "Load NetD  6\n",
            "Load NetD  7\n",
            "Load NetD  8\n",
            "Load NetD  9\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source/main.py\", line 358, in <module>\n",
            "    main(args)\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source/main.py\", line 180, in main\n",
            "    netD.load_state_dict(torch.load(network_path))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 999, in load\n",
            "    if _is_zipfile(opened_file):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 120, in _is_zipfile\n",
            "    read_bytes = f.read(len(local_header_magic_number))\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python main.py -data 'mnist' -name 'ResNet_default' -ldir '../results/mnist/pretrain/ResNet_default'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With 20,000 main training iterations and 2000 added as warm start it is not feasible to train the architectures as with multiple iterations we have to ensure that the discriminator or generator doesn't become too powerful."
      ],
      "metadata": {
        "id": "GM5dFh_j6Q1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution:"
      ],
      "metadata": {
        "id": "Zit-o0Yl64Wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"Transfer Learning\""
      ],
      "metadata": {
        "id": "YzuL9Aaq67Gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With the appropriate architectures, we aim to derive excellent weights and then deploy the generator models to evaluate our approach"
      ],
      "metadata": {
        "id": "yYuDwB947ErT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHxXXUAW3tbj"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gUN4oya3tHV",
        "outputId": "9ccb4228-6d46-41e7-c328-f9c33978d718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/evaluation\n"
          ]
        }
      ],
      "source": [
        "%cd evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SehXd634xDo"
      },
      "source": [
        "##1.Privacy Cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za_khp7KpxOC",
        "outputId": "25725067-cfb1-4c04-d84c-95ac44f11c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Privacy cost is: epsilon=9.992624296723676, delta=1e-05\n"
          ]
        }
      ],
      "source": [
        "!python privacy_analysis.py -data 'mnist' -name 'ResNet_default'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzdsOgBR4z56"
      },
      "source": [
        "##2.Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y034ZiDhFcHh",
        "outputId": "6f928b9b-b936-4dd2-be02-0a656264af64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/evaluation\n"
          ]
        }
      ],
      "source": [
        "%cd ../evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCaghKJd30pA",
        "outputId": "cd9acb4f-d301-4006-ef7b-943668114da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/evaluation/eval_sklearn.py\", line 227, in <module>\n",
            "    main(parse_arguments())\n",
            "  File \"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/evaluation/eval_sklearn.py\", line 116, in main\n",
            "    gen_data = np.load(args.gen_data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 462, in load\n",
            "    raise ValueError(\"Cannot load file containing pickled data \"\n",
            "ValueError: Cannot load file containing pickled data when allow_pickle=False\n"
          ]
        }
      ],
      "source": [
        "!python eval_sklearn.py --gen_data './../results/mnist/main/ResNet_default/netGS.pth' -data 'mnist'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrZuQM1R5C8e",
        "outputId": "17b1328f-d30b-4d35-c778-94b3affadc65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: eval_sklearn.py [-h] [--gen_data GEN_DATA] [--save_dir SAVE_DIR]\n",
            "                       [--dataset {mnist,fashionmnist}] [--if_print_conf_mat]\n",
            "                       [--if_skip_slow_models] [--if_only_slow_models] [--if_compute_real_to_real]\n",
            "                       [--if_skip_gen_to_real] [--if_skip_real_to_gen]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --gen_data GEN_DATA   path of file that store the generated data\n",
            "  --save_dir SAVE_DIR   output folder name; will be automatically save to the folder of gen_data\n",
            "                        if not specified\n",
            "  --dataset {mnist,fashionmnist}, -data {mnist,fashionmnist}\n",
            "                        dataset name\n",
            "  --if_print_conf_mat   print confusion matrix\n",
            "  --if_skip_slow_models\n",
            "                        skip models that take longer\n",
            "  --if_only_slow_models\n",
            "                        only do slower the models\n",
            "  --if_compute_real_to_real\n",
            "                        add train:real,test:real\n",
            "  --if_skip_gen_to_real\n",
            "                        skip train:gen,test:real setting\n",
            "  --if_skip_real_to_gen\n",
            "                        add train:real,test:gen\n"
          ]
        }
      ],
      "source": [
        "!python eval_sklearn.py -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ptyQJ-nF-aL3",
        "outputId": "3fe2e9da-1c23-44c2-bf9e-ac2a50a69c4a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1zOq3j9sgb3a6ckE7CYdVuoQTgI6C-ogo/AI_Project _stuff/GS-WGAN'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbC3lh0cD5aJ",
        "outputId": "edf41a00-5757-4d68-fd71-24fc821cfdb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source\n"
          ]
        }
      ],
      "source": [
        "%cd ../source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EirUlXTzD85u",
        "outputId": "7cd39709-4ef2-4287-e979-546522de8da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] [--random_seed RANDOM_SEED] [--dataset {mnist,fashionmnist}]\n",
            "               [--num_discriminators NUM_DISCRIMINATORS] [--noise_multiplier NOISE_MULTIPLIER]\n",
            "               [--z_dim Z_DIM] [--model_dim MODEL_DIM] [--batchsize BATCHSIZE] [--L_gp L_GP]\n",
            "               [--L_epsilon L_EPSILON] [--critic_iters CRITIC_ITERS]\n",
            "               [--latent_type {normal,bernoulli}] [--iterations ITERATIONS]\n",
            "               [--pretrain_iterations PRETRAIN_ITERATIONS] [--num_workers NUM_WORKERS]\n",
            "               [--net_ids NET_IDS [NET_IDS ...]] [--print_step PRINT_STEP] [--vis_step VIS_STEP]\n",
            "               [--save_step SAVE_STEP] [--load_dir LOAD_DIR] [--pretrain] [--num_gpus NUM_GPUS]\n",
            "               [--gen_arch {DCGAN,ResNet}] [--run RUN] [--exp_name EXP_NAME]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --random_seed RANDOM_SEED, -s RANDOM_SEED\n",
            "                        random seed\n",
            "  --dataset {mnist,fashionmnist}, -data {mnist,fashionmnist}\n",
            "                        dataset name\n",
            "  --num_discriminators NUM_DISCRIMINATORS, -ndis NUM_DISCRIMINATORS\n",
            "                        number of discriminators\n",
            "  --noise_multiplier NOISE_MULTIPLIER, -noise NOISE_MULTIPLIER\n",
            "                        noise multiplier\n",
            "  --z_dim Z_DIM, -zdim Z_DIM\n",
            "                        latent code dimensionality\n",
            "  --model_dim MODEL_DIM, -mdim MODEL_DIM\n",
            "                        model dimensionality\n",
            "  --batchsize BATCHSIZE, -bs BATCHSIZE\n",
            "                        batch size\n",
            "  --L_gp L_GP, -lgp L_GP\n",
            "                        gradient penalty lambda hyperparameter\n",
            "  --L_epsilon L_EPSILON, -lep L_EPSILON\n",
            "                        epsilon penalty (used in PGGAN)\n",
            "  --critic_iters CRITIC_ITERS, -diters CRITIC_ITERS\n",
            "                        number of critic iters per gen iter\n",
            "  --latent_type {normal,bernoulli}, -latent {normal,bernoulli}\n",
            "                        latent distribution\n",
            "  --iterations ITERATIONS, -iters ITERATIONS\n",
            "                        iterations for training\n",
            "  --pretrain_iterations PRETRAIN_ITERATIONS, -piters PRETRAIN_ITERATIONS\n",
            "                        iterations for pre-training\n",
            "  --num_workers NUM_WORKERS, -nwork NUM_WORKERS\n",
            "                        number of workers\n",
            "  --net_ids NET_IDS [NET_IDS ...], -ids NET_IDS [NET_IDS ...]\n",
            "                        the index list for the discriminator\n",
            "  --print_step PRINT_STEP, -pstep PRINT_STEP\n",
            "                        number of steps to print\n",
            "  --vis_step VIS_STEP, -vstep VIS_STEP\n",
            "                        number of steps to vis & eval\n",
            "  --save_step SAVE_STEP, -sstep SAVE_STEP\n",
            "                        number of steps to save\n",
            "  --load_dir LOAD_DIR, -ldir LOAD_DIR\n",
            "                        checkpoint dir (for loading pre-trained models)\n",
            "  --pretrain            if performing pre-training\n",
            "  --num_gpus NUM_GPUS, -ngpus NUM_GPUS\n",
            "                        number of gpus\n",
            "  --gen_arch {DCGAN,ResNet}, -gen {DCGAN,ResNet}\n",
            "                        generator architecture\n",
            "  --run RUN, -run RUN   index number of run\n",
            "  --exp_name EXP_NAME, -name EXP_NAME\n",
            "                        output folder name; will be automatically generated if not specified\n"
          ]
        }
      ],
      "source": [
        "!python main.py -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0MbC7E3JEGP_",
        "outputId": "d7272a4c-4094-428e-9047-672923d5db44"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PZ9XQXVTPA0a",
        "outputId": "041beb1e-d458-44b1-b60b-ed7930640013"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t1xqX8DPEse",
        "outputId": "8595ca3f-e820-4e58-b813-5476ae83c10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config.py  models.py  pretrain.py  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/        slurm.sh\n",
            "main.py    ops.py     pretrain.sh  sanity_check.ipynb  utils.py\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intensive Code Analysis and Scripting to achieve Generative Data File"
      ],
      "metadata": {
        "id": "_ypSr_GZ-YnS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRmAPrSwMI5y",
        "outputId": "041597d0-beb3-40ef-fd98-e975da99eefe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from config import *\n",
        "from models import *\n",
        "from utils import *\n",
        "\n",
        "from ops import exp_mov_avg\n",
        "\n",
        "z_dim=10\n",
        "model_dim=64\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "devices = [torch.device(\"cuda:%d\" % i if use_cuda else \"cpu\") for i in range(1)]\n",
        "device0 = devices[0]\n",
        "if use_cuda:\n",
        "\ttorch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "latent_type=\"bernoulli\"\n",
        "if latent_type == 'bernoulli':\n",
        "        p = 0.5\n",
        "        bernoulli = torch.distributions.Bernoulli(torch.tensor([p]))\n",
        "        fix_noise = bernoulli.sample((10, z_dim)).view(10, z_dim)\n",
        "\n",
        "netG = GeneratorResNet(z_dim=z_dim, model_dim=model_dim, num_classes=10)\n",
        "netGS = copy.deepcopy(netG)\n",
        "\n",
        "netGS.load_state_dict(torch.load(\"/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/results/mnist/main/ResNet_default/netGS.pth\"))\n",
        "netGS.eval()\n",
        "\n",
        "save_gen_data((\"./../results/mnist/main/ResNet_default/gen_data.npz\"), netGS, z_dim, device0, latent_type=latent_type)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7VJn0Io8QwWw",
        "outputId": "6a331a02-0224-46b2-8651-d3ecf68e0d51"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/source'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNmODNqHUuWx",
        "outputId": "9a6b50c4-2fa4-44a9-9bed-3fb5c0d77afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_Project _stuff/GS-WGAN/evaluation\n"
          ]
        }
      ],
      "source": [
        "%cd ../evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWaBVVt9U1vM",
        "outputId": "fa4f6394-09c0-4948-ebf4-e11fee0a4fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n",
            "data ranges: [0.0,1.0], [0.0,1.0],[5.395195785240503e-06,0.999640703201294]\n",
            "label ranges: [0,9], [0,9],[0,9]\n",
            "Model: adaboost\n",
            "acc: real -1, gen to real 0.2735, real to gen 0.5357\n",
            "f1:  real -1, gen to real 0.1416723358249929, real to gen 0.5119568880481671\n",
            "Model: bagging\n",
            "acc: real -1, gen to real 0.4309, real to gen 0.6281\n",
            "f1:  real -1, gen to real 0.37804247556294857, real to gen 0.608296745501123\n",
            "Model: bernoulli_nb\n",
            "acc: real -1, gen to real 0.7358, real to gen 0.9881\n",
            "f1:  real -1, gen to real 0.7437387617383311, real to gen 0.9880882170554379\n",
            "Model: decision_tree\n",
            "acc: real -1, gen to real 0.3356, real to gen 0.4764\n",
            "f1:  real -1, gen to real 0.26017564517741654, real to gen 0.4467654269408142\n",
            "Model: gaussian_nb\n",
            "acc: real -1, gen to real 0.6203, real to gen 0.4256\n",
            "f1:  real -1, gen to real 0.6298108062287249, real to gen 0.3505414336752603\n",
            "Model: gbm\n",
            "acc: real -1, gen to real 0.3859, real to gen 0.7385\n",
            "f1:  real -1, gen to real 0.3495133056054362, real to gen 0.6983296159347394\n",
            "Model: lda\n",
            "acc: real -1, gen to real 0.7627, real to gen 0.9969\n",
            "f1:  real -1, gen to real 0.761227071387527, real to gen 0.996906196489635\n",
            "Model: linear_svc\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "acc: real -1, gen to real 0.7524, real to gen 0.9945\n",
            "f1:  real -1, gen to real 0.7510642742381816, real to gen 0.9945125267147192\n",
            "Model: logistic_reg\n",
            "acc: real -1, gen to real 0.7912, real to gen 0.9948\n",
            "f1:  real -1, gen to real 0.7895610202340412, real to gen 0.9948100599634803\n",
            "Model: mlp\n",
            "acc: real -1, gen to real 0.7793, real to gen 0.9879\n",
            "f1:  real -1, gen to real 0.7759223060686156, real to gen 0.9878836707682781\n",
            "Model: random_forest\n",
            "acc: real -1, gen to real 0.5157, real to gen 0.7188\n",
            "f1:  real -1, gen to real 0.4610022651785573, real to gen 0.7035819215657952\n",
            "Model: xgboost\n",
            "acc: real -1, gen to real 0.4223, real to gen 0.7016\n",
            "f1:  real -1, gen to real 0.35174671896477766, real to gen 0.6997507894704256\n"
          ]
        }
      ],
      "source": [
        "!python eval_sklearn.py --gen_data './../results/mnist/main/ResNet_default/gen_data.npz' -data 'mnist'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi39stczgKIS"
      },
      "source": [
        "### CNN Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ugkrXaeU6MY",
        "outputId": "0cf8e7d6-5488-4083-97db-8aff3f787eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1zOq3j9sgb3a6ckE7CYdVuoQTgI6C-ogo/AI_Project _stuff/GS-WGAN/evaluation\n"
          ]
        }
      ],
      "source": [
        "%cd evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EhOKSTUgQC_",
        "outputId": "001a13a6-1b72-45ee-ed8d-7637dd3c4faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gen_data:./../results/mnist/main/ResNet_default/gen_data.npz\n",
            "save_dir:None\n",
            "model_architecture:lenet\n",
            "dataset:mnist\n",
            "random_seed:1000\n",
            "lr:0.02\n",
            "schedule_milestone:[40]\n",
            "gamma:0.1\n",
            "weight_decay:0.0001\n",
            "momentum:0.9\n",
            "train_batchsize:128\n",
            "test_batchsize:128\n",
            "num_workers:0\n",
            "num_epochs:50\n",
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([60000])\n",
            "Processing |################################| (469/469) | Loss: 0.1784 | top1:  94.5167 | top5:  98.4567\n",
            "Processing |################################| (79/79)| Loss: 2.0644 | top1:  77.4000 | top5:  97.3200\n",
            "Epoch 0, Train acc: 94.516667, Test acc: 77.400000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 2.0299 | top1:  77.7700 | top5:  97.2800\n",
            "Epoch 1, Train acc: 100.000000, Test acc: 77.770000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.9958 | top1:  77.8000 | top5:  97.2900\n",
            "Epoch 2, Train acc: 100.000000, Test acc: 77.800000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.9685 | top1:  77.9200 | top5:  97.3000\n",
            "Epoch 3, Train acc: 100.000000, Test acc: 77.920000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.9420 | top1:  77.8700 | top5:  97.3600\n",
            "Epoch 4, Train acc: 100.000000, Test acc: 77.870000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.9123 | top1:  78.0200 | top5:  97.3200\n",
            "Epoch 5, Train acc: 100.000000, Test acc: 78.020000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.8822 | top1:  77.9000 | top5:  97.3800\n",
            "Epoch 6, Train acc: 100.000000, Test acc: 77.900000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.8599 | top1:  78.0100 | top5:  97.3900\n",
            "Epoch 7, Train acc: 100.000000, Test acc: 78.010000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.8379 | top1:  77.8900 | top5:  97.4000\n",
            "Epoch 8, Train acc: 100.000000, Test acc: 77.890000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.8219 | top1:  77.7400 | top5:  97.4000\n",
            "Epoch 9, Train acc: 100.000000, Test acc: 77.740000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.7997 | top1:  77.9800 | top5:  97.3900\n",
            "Epoch 10, Train acc: 100.000000, Test acc: 77.980000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.7866 | top1:  77.8600 | top5:  97.4000\n",
            "Epoch 11, Train acc: 100.000000, Test acc: 77.860000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.7651 | top1:  77.9400 | top5:  97.4500\n",
            "Epoch 12, Train acc: 100.000000, Test acc: 77.940000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.7539 | top1:  77.9800 | top5:  97.4300\n",
            "Epoch 13, Train acc: 100.000000, Test acc: 77.980000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.7385 | top1:  78.1100 | top5:  97.4200\n",
            "Epoch 14, Train acc: 100.000000, Test acc: 78.110000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.7302 | top1:  78.0900 | top5:  97.4600\n",
            "Epoch 15, Train acc: 100.000000, Test acc: 78.090000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.7150 | top1:  78.1700 | top5:  97.4300\n",
            "Epoch 16, Train acc: 100.000000, Test acc: 78.170000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.7051 | top1:  78.2000 | top5:  97.4600\n",
            "Epoch 17, Train acc: 100.000000, Test acc: 78.200000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6925 | top1:  78.3100 | top5:  97.4600\n",
            "Epoch 18, Train acc: 100.000000, Test acc: 78.310000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6864 | top1:  78.1600 | top5:  97.4900\n",
            "Epoch 19, Train acc: 100.000000, Test acc: 78.160000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6787 | top1:  78.2900 | top5:  97.4600\n",
            "Epoch 20, Train acc: 100.000000, Test acc: 78.290000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6684 | top1:  78.3000 | top5:  97.4500\n",
            "Epoch 21, Train acc: 100.000000, Test acc: 78.300000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6619 | top1:  78.2500 | top5:  97.4300\n",
            "Epoch 22, Train acc: 100.000000, Test acc: 78.250000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6568 | top1:  78.2400 | top5:  97.4600\n",
            "Epoch 23, Train acc: 100.000000, Test acc: 78.240000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6496 | top1:  78.3300 | top5:  97.4100\n",
            "Epoch 24, Train acc: 100.000000, Test acc: 78.330000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6422 | top1:  78.3200 | top5:  97.4800\n",
            "Epoch 25, Train acc: 100.000000, Test acc: 78.320000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6305 | top1:  78.2600 | top5:  97.4700\n",
            "Epoch 26, Train acc: 100.000000, Test acc: 78.260000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6246 | top1:  78.2800 | top5:  97.4700\n",
            "Epoch 27, Train acc: 100.000000, Test acc: 78.280000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6250 | top1:  78.1000 | top5:  97.4500\n",
            "Epoch 28, Train acc: 100.000000, Test acc: 78.100000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6193 | top1:  78.2800 | top5:  97.4100\n",
            "Epoch 29, Train acc: 100.000000, Test acc: 78.280000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6119 | top1:  78.3100 | top5:  97.4100\n",
            "Epoch 30, Train acc: 100.000000, Test acc: 78.310000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6126 | top1:  78.2800 | top5:  97.3800\n",
            "Epoch 31, Train acc: 100.000000, Test acc: 78.280000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6071 | top1:  78.2200 | top5:  97.3500\n",
            "Epoch 32, Train acc: 100.000000, Test acc: 78.220000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6072 | top1:  78.1400 | top5:  97.3400\n",
            "Epoch 33, Train acc: 100.000000, Test acc: 78.140000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.6015 | top1:  78.2000 | top5:  97.3500\n",
            "Epoch 34, Train acc: 100.000000, Test acc: 78.200000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5932 | top1:  78.2600 | top5:  97.3400\n",
            "Epoch 35, Train acc: 100.000000, Test acc: 78.260000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5953 | top1:  78.1400 | top5:  97.3400\n",
            "Epoch 36, Train acc: 100.000000, Test acc: 78.140000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5953 | top1:  78.0400 | top5:  97.3700\n",
            "Epoch 37, Train acc: 100.000000, Test acc: 78.040000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5964 | top1:  78.0100 | top5:  97.3400\n",
            "Epoch 38, Train acc: 100.000000, Test acc: 78.010000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5921 | top1:  77.9800 | top5:  97.3500\n",
            "Epoch 39, Train acc: 100.000000, Test acc: 77.980000, lr: 0.020000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5895 | top1:  78.0700 | top5:  97.3400\n",
            "Epoch 40, Train acc: 100.000000, Test acc: 78.070000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5892 | top1:  78.0900 | top5:  97.3400\n",
            "Epoch 41, Train acc: 100.000000, Test acc: 78.090000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5895 | top1:  78.0800 | top5:  97.3500\n",
            "Epoch 42, Train acc: 100.000000, Test acc: 78.080000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5894 | top1:  78.0500 | top5:  97.3500\n",
            "Epoch 43, Train acc: 100.000000, Test acc: 78.050000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5897 | top1:  78.0400 | top5:  97.3500\n",
            "Epoch 44, Train acc: 100.000000, Test acc: 78.040000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5899 | top1:  78.0400 | top5:  97.3600\n",
            "Epoch 45, Train acc: 100.000000, Test acc: 78.040000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5891 | top1:  78.0400 | top5:  97.3600\n",
            "Epoch 46, Train acc: 100.000000, Test acc: 78.040000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5891 | top1:  78.0500 | top5:  97.3600\n",
            "Epoch 47, Train acc: 100.000000, Test acc: 78.050000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5889 | top1:  78.0600 | top5:  97.3600\n",
            "Epoch 48, Train acc: 100.000000, Test acc: 78.060000, lr: 0.002000\n",
            "Processing |################################| (469/469) | Loss: 0.0000 | top1:  100.0000 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 1.5887 | top1:  78.0400 | top5:  97.3800\n",
            "Epoch 49, Train acc: 100.000000, Test acc: 78.040000, lr: 0.002000\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!python eval_cnn.py --gen_data './../results/mnist/main/ResNet_default/gen_data.npz' -data 'mnist'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeBGQBFXhqzr"
      },
      "source": [
        "### MNIST Inception Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TZoNWMTZgUME",
        "outputId": "f0a0ab8e-c052-4afd-958f-417169c82168"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1zOq3j9sgb3a6ckE7CYdVuoQTgI6C-ogo/AI_Project _stuff/GS-WGAN/evaluation'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjeDQrbHfLhk"
      },
      "source": [
        "Training a classifier on real data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldeU94XJhynX",
        "outputId": "451ea861-7b12-4daf-d4f8-8a6cabe2b6d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_architecture:vgg11\n",
            "exp_name:vgg11\n",
            "dataset:mnist\n",
            "random_seed:1000\n",
            "lr:0.1\n",
            "schedule_milestone:[40]\n",
            "gamma:0.1\n",
            "weight_decay:0.0001\n",
            "momentum:0.9\n",
            "train_batchsize:128\n",
            "test_batchsize:128\n",
            "num_workers:0\n",
            "num_epochs:50\n",
            "With data augmentation\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (29): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  )\n",
            "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Total params: 9229962.00\n",
            "Processing |################################| (469/469) | Loss: 2.1225 | top1:  32.6817 | top5:  84.5350\n",
            "Processing |################################| (79/79)| Loss: 1.0872 | top1:  57.7800 | top5:  97.3300\n",
            "Epoch 0, Train acc: 32.681667, Test acc: 57.780000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.4433 | top1:  85.0617 | top5:  99.1133\n",
            "Processing |################################| (79/79)| Loss: 0.2271 | top1:  92.4200 | top5:  99.7600\n",
            "Epoch 1, Train acc: 85.061667, Test acc: 92.420000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.1627 | top1:  94.9283 | top5:  99.8283\n",
            "Processing |################################| (79/79)| Loss: 0.1524 | top1:  95.0200 | top5:  99.7900\n",
            "Epoch 2, Train acc: 94.928333, Test acc: 95.020000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.1147 | top1:  96.3983 | top5:  99.9067\n",
            "Processing |################################| (79/79)| Loss: 0.1414 | top1:  95.5200 | top5:  99.9300 \n",
            "Epoch 3, Train acc: 96.398333, Test acc: 95.520000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0925 | top1:  97.0933 | top5:  99.9450\n",
            "Processing |################################| (79/79)| Loss: 0.0901 | top1:  97.1500 | top5:  99.9600 \n",
            "Epoch 4, Train acc: 97.093333, Test acc: 97.150000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0803 | top1:  97.5067 | top5:  99.9450\n",
            "Processing |################################| (79/79)| Loss: 0.1090 | top1:  96.4500 | top5:  99.9600\n",
            "Epoch 5, Train acc: 97.506667, Test acc: 96.450000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0701 | top1:  97.7750 | top5:  99.9667\n",
            "Processing |################################| (79/79)| Loss: 0.0815 | top1:  97.4900 | top5:  99.9200 \n",
            "Epoch 6, Train acc: 97.775000, Test acc: 97.490000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0653 | top1:  97.9650 | top5:  99.9667\n",
            "Processing |################################| (79/79)| Loss: 0.0528 | top1:  98.3500 | top5:  100.0000\n",
            "Epoch 7, Train acc: 97.965000, Test acc: 98.350000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0603 | top1:  98.1267 | top5:  99.9833\n",
            "Processing |################################| (79/79)| Loss: 0.0997 | top1:  96.6400 | top5:  99.9700\n",
            "Epoch 8, Train acc: 98.126667, Test acc: 96.640000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0576 | top1:  98.2633 | top5:  99.9767\n",
            "Processing |################################| (79/79)| Loss: 0.0603 | top1:  97.9500 | top5:  99.9900 \n",
            "Epoch 9, Train acc: 98.263333, Test acc: 97.950000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0530 | top1:  98.4200 | top5:  99.9800\n",
            "Processing |################################| (79/79)| Loss: 0.0432 | top1:  98.5100 | top5:  99.9900 \n",
            "Epoch 10, Train acc: 98.420000, Test acc: 98.510000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0528 | top1:  98.3317 | top5:  99.9850 \n",
            "Processing |################################| (79/79)| Loss: 0.0673 | top1:  97.9400 | top5:  99.9500\n",
            "Epoch 11, Train acc: 98.331667, Test acc: 97.940000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0519 | top1:  98.3300 | top5:  99.9883\n",
            "Processing |################################| (79/79)| Loss: 0.0636 | top1:  97.8600 | top5:  99.9600 \n",
            "Epoch 12, Train acc: 98.330000, Test acc: 97.860000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0466 | top1:  98.5450 | top5:  99.9783\n",
            "Processing |################################| (79/79)| Loss: 0.0423 | top1:  98.5700 | top5:  99.9800 \n",
            "Epoch 13, Train acc: 98.545000, Test acc: 98.570000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0462 | top1:  98.5550 | top5:  99.9950 \n",
            "Processing |################################| (79/79)| Loss: 0.0542 | top1:  98.3700 | top5:  99.9900 \n",
            "Epoch 14, Train acc: 98.555000, Test acc: 98.370000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0454 | top1:  98.5650 | top5:  99.9867\n",
            "Processing |################################| (79/79)| Loss: 0.0565 | top1:  98.1000 | top5:  100.0000\n",
            "Epoch 15, Train acc: 98.565000, Test acc: 98.100000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0439 | top1:  98.6067 | top5:  99.9883\n",
            "Processing |################################| (79/79)| Loss: 0.0520 | top1:  98.3200 | top5:  99.9900\n",
            "Epoch 16, Train acc: 98.606667, Test acc: 98.320000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0445 | top1:  98.5983 | top5:  99.9867\n",
            "Processing |################################| (79/79)| Loss: 0.0669 | top1:  97.7500 | top5:  99.9900 \n",
            "Epoch 17, Train acc: 98.598333, Test acc: 97.750000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0427 | top1:  98.6633 | top5:  99.9933\n",
            "Processing |################################| (79/79)| Loss: 0.0523 | top1:  98.3000 | top5:  100.0000\n",
            "Epoch 18, Train acc: 98.663333, Test acc: 98.300000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0404 | top1:  98.6967 | top5:  99.9950\n",
            "Processing |################################| (79/79)| Loss: 0.0703 | top1:  97.6600 | top5:  100.0000\n",
            "Epoch 19, Train acc: 98.696667, Test acc: 97.660000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0428 | top1:  98.6250 | top5:  99.9950 \n",
            "Processing |################################| (79/79)| Loss: 0.0567 | top1:  98.1500 | top5:  99.9900\n",
            "Epoch 20, Train acc: 98.625000, Test acc: 98.150000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0405 | top1:  98.7367 | top5:  99.9933 \n",
            "Processing |################################| (79/79)| Loss: 0.0597 | top1:  98.1300 | top5:  99.9900\n",
            "Epoch 21, Train acc: 98.736667, Test acc: 98.130000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0420 | top1:  98.6400 | top5:  99.9917\n",
            "Processing |################################| (79/79)| Loss: 0.0487 | top1:  98.4400 | top5:  99.9900 \n",
            "Epoch 22, Train acc: 98.640000, Test acc: 98.440000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0403 | top1:  98.7417 | top5:  99.9950\n",
            "Processing |################################| (79/79)| Loss: 0.0586 | top1:  98.0000 | top5:  99.9800\n",
            "Epoch 23, Train acc: 98.741667, Test acc: 98.000000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0406 | top1:  98.7450 | top5:  99.9933 \n",
            "Processing |################################| (79/79)| Loss: 0.0472 | top1:  98.4400 | top5:  100.0000\n",
            "Epoch 24, Train acc: 98.745000, Test acc: 98.440000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0388 | top1:  98.7817 | top5:  99.9900\n",
            "Processing |################################| (79/79)| Loss: 0.0490 | top1:  98.5400 | top5:  99.9900 \n",
            "Epoch 25, Train acc: 98.781667, Test acc: 98.540000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0375 | top1:  98.7700 | top5:  99.9950 \n",
            "Processing |################################| (79/79)| Loss: 0.0715 | top1:  97.7800 | top5:  99.9700\n",
            "Epoch 26, Train acc: 98.770000, Test acc: 97.780000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0388 | top1:  98.7717 | top5:  99.9900\n",
            "Processing |################################| (79/79)| Loss: 0.0489 | top1:  98.3900 | top5:  99.9800 \n",
            "Epoch 27, Train acc: 98.771667, Test acc: 98.390000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0377 | top1:  98.8267 | top5:  99.9900\n",
            "Processing |################################| (79/79)| Loss: 0.0452 | top1:  98.6400 | top5:  99.9700\n",
            "Epoch 28, Train acc: 98.826667, Test acc: 98.640000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0382 | top1:  98.7883 | top5:  99.9967\n",
            "Processing |################################| (79/79)| Loss: 0.0704 | top1:  97.8600 | top5:  99.9700 \n",
            "Epoch 29, Train acc: 98.788333, Test acc: 97.860000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0381 | top1:  98.8383 | top5:  99.9917\n",
            "Processing |################################| (79/79)| Loss: 0.0562 | top1:  98.3100 | top5:  99.9900 \n",
            "Epoch 30, Train acc: 98.838333, Test acc: 98.310000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0355 | top1:  98.8217 | top5:  99.9933\n",
            "Processing |################################| (79/79)| Loss: 0.0494 | top1:  98.4400 | top5:  99.9800 \n",
            "Epoch 31, Train acc: 98.821667, Test acc: 98.440000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0370 | top1:  98.8050 | top5:  99.9950\n",
            "Processing |################################| (79/79)| Loss: 0.0424 | top1:  98.6300 | top5:  99.9900 \n",
            "Epoch 32, Train acc: 98.805000, Test acc: 98.630000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0379 | top1:  98.7933 | top5:  99.9900 \n",
            "Processing |################################| (79/79)| Loss: 0.0571 | top1:  98.3300 | top5:  100.0000\n",
            "Epoch 33, Train acc: 98.793333, Test acc: 98.330000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0366 | top1:  98.8483 | top5:  99.9933 \n",
            "Processing |################################| (79/79)| Loss: 0.0538 | top1:  98.4800 | top5:  99.9800 \n",
            "Epoch 34, Train acc: 98.848333, Test acc: 98.480000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0366 | top1:  98.8600 | top5:  99.9950\n",
            "Processing |################################| (79/79)| Loss: 0.0524 | top1:  98.4600 | top5:  99.9800 \n",
            "Epoch 35, Train acc: 98.860000, Test acc: 98.460000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0368 | top1:  98.7967 | top5:  99.9900\n",
            "Processing |################################| (79/79)| Loss: 0.0562 | top1:  98.1300 | top5:  99.9900 \n",
            "Epoch 36, Train acc: 98.796667, Test acc: 98.130000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0358 | top1:  98.8517 | top5:  99.9967\n",
            "Processing |################################| (79/79)| Loss: 0.0444 | top1:  98.6100 | top5:  99.9900 \n",
            "Epoch 37, Train acc: 98.851667, Test acc: 98.610000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0378 | top1:  98.8367 | top5:  99.9917 \n",
            "Processing |################################| (79/79)| Loss: 0.0594 | top1:  98.0600 | top5:  100.0000\n",
            "Epoch 38, Train acc: 98.836667, Test acc: 98.060000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0353 | top1:  98.8417 | top5:  99.9950\n",
            "Processing |################################| (79/79)| Loss: 0.0348 | top1:  98.9300 | top5:  100.0000\n",
            "Epoch 39, Train acc: 98.841667, Test acc: 98.930000, lr: 0.100000\n",
            "Processing |################################| (469/469) | Loss: 0.0211 | top1:  99.3383 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0314 | top1:  98.9700 | top5:  100.0000\n",
            "Epoch 40, Train acc: 99.338333, Test acc: 98.970000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0182 | top1:  99.4033 | top5:  99.9983 \n",
            "Processing |################################| (79/79)| Loss: 0.0287 | top1:  99.0600 | top5:  100.0000\n",
            "Epoch 41, Train acc: 99.403333, Test acc: 99.060000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0168 | top1:  99.4367 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0312 | top1:  99.0100 | top5:  99.9800 \n",
            "Epoch 42, Train acc: 99.436667, Test acc: 99.010000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0166 | top1:  99.4567 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0283 | top1:  99.1100 | top5:  99.9900 \n",
            "Epoch 43, Train acc: 99.456667, Test acc: 99.110000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0160 | top1:  99.5017 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0281 | top1:  99.1300 | top5:  100.0000\n",
            "Epoch 44, Train acc: 99.501667, Test acc: 99.130000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0154 | top1:  99.5100 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0276 | top1:  99.1200 | top5:  100.0000\n",
            "Epoch 45, Train acc: 99.510000, Test acc: 99.120000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0154 | top1:  99.5167 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0269 | top1:  99.1000 | top5:  100.0000\n",
            "Epoch 46, Train acc: 99.516667, Test acc: 99.100000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0137 | top1:  99.5650 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0284 | top1:  99.1000 | top5:  100.0000\n",
            "Epoch 47, Train acc: 99.565000, Test acc: 99.100000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0141 | top1:  99.5467 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0287 | top1:  99.0400 | top5:  100.0000\n",
            "Epoch 48, Train acc: 99.546667, Test acc: 99.040000, lr: 0.010000\n",
            "Processing |################################| (469/469) | Loss: 0.0134 | top1:  99.5833 | top5:  100.0000\n",
            "Processing |################################| (79/79)| Loss: 0.0275 | top1:  99.1100 | top5:  99.9900\n",
            "Epoch 49, Train acc: 99.583333, Test acc: 99.110000, lr: 0.010000\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!python train_mnist_inception_score.py -data 'mnist'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKtHEQMmfQEu"
      },
      "source": [
        "Caluating IS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opflH1vih_RD",
        "outputId": "2802929f-6f63-4779-8393-ff2a3e769426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mnist inception score (model: /content/drive/.shortcut-targets-by-id/1zOq3j9sgb3a6ckE7CYdVuoQTgI6C-ogo/AI_Project _stuff/GS-WGAN/evaluation/models/mnist/vgg11) : mean  9.127073287963867 std 0.03446761146187782\n"
          ]
        }
      ],
      "source": [
        "!python eval_mnist_inception_score.py -data 'mnist' --gen_data './../results/mnist/main/ResNet_default/gen_data.npz'\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}